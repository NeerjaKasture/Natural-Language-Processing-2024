# CS 613: NLP
## Assignment 1: Data Preparation and De-duplication

Link to HuggingFace repository containing the scraped datasets - https://huggingface.co/datasets/snehagautam/nlp_webscraping/tree/main

Contribution:

Sneha Gautam - Deduplication code - Sim hash & Cosine similarity, 
Extraction : Express, Taasir, Wikipedia, Jang, Urdu Point, Urdu Zone, Siasat - entertainment, India, world, arab_world, HindustanExpress, Archive 
Deduplication

Anura Mantri - Deduplication code - Min hash, 
Extraction : Internet Archives, News18

Neerja Kasture - Bad words dictionary, Data cleaning code, 
Extraction : BBC Urdu, Siasat - city, crime

Apart from this, everyone scraped their own data using different libraries and cleaned them individually.

